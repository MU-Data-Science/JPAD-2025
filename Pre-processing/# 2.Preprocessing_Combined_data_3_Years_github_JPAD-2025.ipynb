{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9816416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "\n",
    "case_data_4Yrs = pd.read_csv('3yrs_Case_Data.csv')\n",
    "control_data_4Yrs = pd.read_csv('3yrs_Control_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique PATID values in each DataFrame\n",
    "print(\"Number of unique PATID values in case_data:\", case_data['PATID'].nunique())\n",
    "print(\"Number of unique PATID values in control_data:\", control_data['PATID'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ef624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two datasets along the rows\n",
    "data = pd.concat([case_data, control_data], ignore_index=True)\n",
    "\n",
    "# Print the combined DataFrame info to verify the changes\n",
    "print(data.info())\n",
    "\n",
    "# Print the first few rows to check the result\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2ae532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATID               0\n",
      "Sex                 0\n",
      "Race                6\n",
      "Marital_Status     13\n",
      "Max_DBP            56\n",
      "Max_SBP            40\n",
      "Min_DBP            56\n",
      "Min_SBP            40\n",
      "Comorbidities     639\n",
      "Smoking_Status    350\n",
      "Encounter Type      0\n",
      "Age_Grp             0\n",
      "Target              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the number of missing values per column\n",
    "\n",
    "data.isnull().sum(axis=0)\n",
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301f6e2",
   "metadata": {},
   "source": [
    "# Check for Symmetry and skewness to decide whether to use the mean, median or mode for imputing missing values in numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13233da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123261 entries, 0 to 123260\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   PATID           123261 non-null  int64  \n",
      " 1   Sex             123261 non-null  object \n",
      " 2   Race            123255 non-null  object \n",
      " 3   Marital_Status  123248 non-null  object \n",
      " 4   Max_DBP         123205 non-null  float64\n",
      " 5   Max_SBP         123221 non-null  float64\n",
      " 6   Min_DBP         123205 non-null  float64\n",
      " 7   Min_SBP         123221 non-null  float64\n",
      " 8   Comorbidities   122622 non-null  object \n",
      " 9   Smoking_Status  122911 non-null  object \n",
      " 10  Encounter Type  123261 non-null  object \n",
      " 11  Age_Grp         123261 non-null  object \n",
      " 12  Target          123261 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81161fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Missing Values  Percentage Missing\n",
      "PATID                        0            0.000000\n",
      "Sex                          0            0.000000\n",
      "Race                         6            0.004868\n",
      "Marital_Status              13            0.010547\n",
      "Max_DBP                     56            0.045432\n",
      "Max_SBP                     40            0.032451\n",
      "Min_DBP                     56            0.045432\n",
      "Min_SBP                     40            0.032451\n",
      "Comorbidities              639            0.518412\n",
      "Smoking_Status             350            0.283950\n",
      "Encounter Type               0            0.000000\n",
      "Age_Grp                      0            0.000000\n",
      "Target                       0            0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values in each column\n",
    "missing_values_after_imputation = data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "percentage_missing = (missing_values_after_imputation / len(data)) * 100\n",
    "\n",
    "# Print the number of missing values and their percentage\n",
    "missing_data_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_values_after_imputation,\n",
    "    'Percentage Missing': percentage_missing\n",
    "})\n",
    "\n",
    "\n",
    "print(missing_data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad8c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numerical columns\n",
    "numerical_columns = ['Max_DBP', 'Max_SBP', 'Min_DBP', 'Min_SBP']\n",
    "\n",
    "for column in numerical_columns:\n",
    "    # Calculate the column skewness\n",
    "    column_skewness = skew(data[column].dropna())\n",
    "    \n",
    "    # Plot the distribution and a boxplot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data[column].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {column} (Skewness: {column_skewness:.2f})')\n",
    "    \n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=data[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(f'{column}_distribution_boxplot.png')\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Decide whether to use mean or median\n",
    "    if abs(column_skewness) < 0.5:\n",
    "        print(f\"{column}: Distribution is fairly symmetric. Impute missing values with mean.\")\n",
    "    else:\n",
    "        print(f\"{column}: Distribution is skewed or has outliers. Impute missing values with median.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b570f",
   "metadata": {},
   "source": [
    "# Impute missing values for the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da4c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with median for skewed distributions or columns with outliers\n",
    "\n",
    "data['Max_DBP'].fillna(data['Max_DBP'].median(), inplace=True)\n",
    "data['Max_SBP'].fillna(data['Max_SBP'].median(), inplace=True)\n",
    "data['Min_SBP'].fillna(data['Min_SBP'].median(), inplace=True)\n",
    "data['Min_DBP'].fillna(data['Min_DBP'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4eb9555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PATID               0\n",
       "Sex                 0\n",
       "Race                6\n",
       "Marital_Status     13\n",
       "Max_DBP             0\n",
       "Max_SBP             0\n",
       "Min_DBP             0\n",
       "Min_SBP             0\n",
       "Comorbidities     639\n",
       "Smoking_Status    350\n",
       "Encounter Type      0\n",
       "Age_Grp             0\n",
       "Target              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values in each column\n",
    "missing_values_after_imputation = data.isnull().sum()\n",
    "missing_values_after_imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87ad02",
   "metadata": {},
   "source": [
    "# Mapping and Encoding Diastolic Blood Pressure (DBP), and Systolic Blood Pressure (SBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35be4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SBP and DBP categories with desired labels\n",
    "data['SBP_Category'] = pd.cut(data['Max_SBP'], bins=[-float('inf'), 120, 140, float('inf')], labels=['SBP <=120', 'SBP 120-140', 'SBP >=140'])\n",
    "data['DBP_Category'] = pd.cut(data['Max_DBP'], bins=[-float('inf'), 80, 90, float('inf')], labels=['DBP <=80', 'DBP 80-90', 'DBP >=90'])\n",
    "\n",
    "# Perform one-hot encoding with the correct names\n",
    "data = pd.get_dummies(data, columns=['SBP_Category', 'DBP_Category'])\n",
    "\n",
    "# Rename the columns to match your format\n",
    "data = data.rename(columns={\n",
    "    'SBP_Category_SBP <=120': 'SBP below 120',\n",
    "    'SBP_Category_SBP 120-140': 'SBP 120-140',\n",
    "    'SBP_Category_SBP >=140': 'SBP above 140',\n",
    "    'DBP_Category_DBP <=80': 'DBP below 80',\n",
    "    'DBP_Category_DBP 80-90': 'DBP 80-90',\n",
    "    'DBP_Category_DBP >=90': 'DBP above 90'\n",
    "})\n",
    "\n",
    "# Remove the original columns\n",
    "data = data.drop(columns=['Max_SBP', 'Min_SBP', 'Max_DBP', 'Min_DBP'])\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(data.head())\n",
    "\n",
    "# Check and print the count for each category\n",
    "print(\"Count for each SBP category:\")\n",
    "print(f\"SBP below 120: {data['SBP below 120'].sum()}\")\n",
    "print(f\"SBP 120-140: {data['SBP 120-140'].sum()}\")\n",
    "print(f\"SBP above 140: {data['SBP above 140'].sum()}\")\n",
    "\n",
    "print(\"\\nCount for each DBP category:\")\n",
    "print(f\"DBP below 80: {data['DBP below 80'].sum()}\")\n",
    "print(f\"DBP 80-90: {data['DBP 80-90'].sum()}\")\n",
    "print(f\"DBP above 90: {data['DBP above 90'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23fd2e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Missing Values  Percentage Missing\n",
      "PATID                        0            0.000000\n",
      "Sex                          0            0.000000\n",
      "Race                         6            0.004868\n",
      "Marital_Status              13            0.010547\n",
      "Comorbidities              639            0.518412\n",
      "Smoking_Status             350            0.283950\n",
      "Encounter Type               0            0.000000\n",
      "Age_Grp                      0            0.000000\n",
      "Target                       0            0.000000\n",
      "SBP below 120                0            0.000000\n",
      "SBP 120-140                  0            0.000000\n",
      "SBP above 140                0            0.000000\n",
      "DBP below 80                 0            0.000000\n",
      "DBP 80-90                    0            0.000000\n",
      "DBP above 90                 0            0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "percentage_missing = (missing_values / len(data)) * 100\n",
    "\n",
    "# Print the number of missing values and their percentage\n",
    "missing_data_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage Missing': percentage_missing\n",
    "})\n",
    "\n",
    "\n",
    "print(missing_data_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52643c67",
   "metadata": {},
   "source": [
    "# Mapping and Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fa757",
   "metadata": {},
   "source": [
    "# 1. Encoding 'Age' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa322690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding on the 'Age_Grp' column\n",
    "age_group_dummies = pd.get_dummies(data['Age_Grp'], prefix='Age_Grp')\n",
    "\n",
    "# Concatenate the original DataFrame with the new one hot encoded columns\n",
    "data = pd.concat([data, age_group_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cdcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf255aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Age_Group' column\n",
    "data = data.drop(columns=['Age_Grp'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54628456",
   "metadata": {},
   "source": [
    "# 2. Imputation, Mapping and Encoding for 'Smoking_Status' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3fe866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value counts for 'Smoking_Status' column:\n",
      "Never smoker                                51640\n",
      "Former smoker quit longer than 12 months    36030\n",
      "Current every day smoker                    31315\n",
      "Current some day smoker                      1976\n",
      "Former smoker quit within 12 months          1475\n",
      "NaN                                           350\n",
      "Light tobacco smoker                          292\n",
      "Heavy tobacco smoker                          121\n",
      "Smoker ###                                     62\n",
      "Name: Smoking_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print initial count\n",
    "\n",
    "initial_count = data['Smoking_Status'].value_counts(dropna=False)\n",
    "print(\"Initial value counts for 'Smoking_Status' column:\")\n",
    "print(initial_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c77615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'Smoking_Status' column after imputation:\n",
      "Never smoker                                51990\n",
      "Former smoker quit longer than 12 months    36030\n",
      "Current every day smoker                    31315\n",
      "Current some day smoker                      1976\n",
      "Former smoker quit within 12 months          1475\n",
      "Light tobacco smoker                          292\n",
      "Heavy tobacco smoker                          121\n",
      "Smoker ###                                     62\n",
      "Name: Smoking_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values (with most frequent value) in the 'Smoking_Status' column\n",
    "\n",
    "data['Smoking_Status'].fillna(data['Smoking_Status'].mode()[0], inplace=True) \n",
    "\n",
    "# Verify the changes after imputation\n",
    "print(\"\\nValue counts for 'Smoking_Status' column after imputation:\")\n",
    "print(data['Smoking_Status'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f6c0ce",
   "metadata": {},
   "source": [
    "# Define the Mapping Function of Smoking_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4872ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and clean the string values in 'Smoking_Status'\n",
    "\n",
    "data['Smoking_Status'] = data['Smoking_Status'].str.replace('#', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a95dee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for encoding\n",
    "\n",
    "smoking_status_mapping = {\n",
    "    'Never smoker': 0,\n",
    "    'Former smoker quit longer than 12 months': 1,\n",
    "    'Former smoker quit within 12 months': 1,\n",
    "    'Light tobacco smoker': 1,\n",
    "    'Current some day smoker': 1,\n",
    "    'Current every day smoker': 1,\n",
    "    'Smoker': 1,\n",
    "    'Heavy tobacco smoker': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2669017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Smoking_Status'] = data['Smoking_Status'].map(smoking_status_mapping)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d10b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    71271\n",
      "0    51990\n",
      "Name: Smoking_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the counts of each category after encoding\n",
    "\n",
    "encoded_counts = data['Smoking_Status'].value_counts()\n",
    "\n",
    "print(encoded_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592ffd3",
   "metadata": {},
   "source": [
    "# 3. Mapping and Encoding 'Sex' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9913dd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'M']\n",
      "  Sex\n",
      "0   F\n",
      "1   F\n",
      "2   F\n",
      "3   M\n",
      "4   F\n",
      "F    66205\n",
      "M    57056\n",
      "Name: Sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the 'Sex' column\n",
    "unique_Sex_Status = data['Sex'].unique()\n",
    "print(unique_Sex_Status)\n",
    "\n",
    "# Verify the new columns and their unique values\n",
    "print(data[['Sex']].head())\n",
    "print(data['Sex'].value_counts(dropna=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2fda38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to the 'Sex' column\n",
    "data = pd.get_dummies(data, columns=['Sex'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa538232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123261 entries, 0 to 123260\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   PATID           123261 non-null  int64 \n",
      " 1   Race            123255 non-null  object\n",
      " 2   Marital_Status  123248 non-null  object\n",
      " 3   Comorbidities   122622 non-null  object\n",
      " 4   Smoking_Status  123261 non-null  int64 \n",
      " 5   Encounter Type  123261 non-null  object\n",
      " 6   Target          123261 non-null  int64 \n",
      " 7   SBP below 120   123261 non-null  uint8 \n",
      " 8   SBP 120-140     123261 non-null  uint8 \n",
      " 9   SBP above 140   123261 non-null  uint8 \n",
      " 10  DBP below 80    123261 non-null  uint8 \n",
      " 11  DBP 80-90       123261 non-null  uint8 \n",
      " 12  DBP above 90    123261 non-null  uint8 \n",
      " 13  Age_Grp_50-60   123261 non-null  uint8 \n",
      " 14  Age_Grp_60-70   123261 non-null  uint8 \n",
      " 15  Age_Grp_70-80   123261 non-null  uint8 \n",
      " 16  Age_Grp_80-90   123261 non-null  uint8 \n",
      " 17  Age_Grp_90-100  123261 non-null  uint8 \n",
      " 18  Sex_F           123261 non-null  uint8 \n",
      " 19  Sex_M           123261 non-null  uint8 \n",
      "dtypes: int64(3), object(4), uint8(13)\n",
      "memory usage: 8.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # Verify the one-hot encoded DataFrame\n",
    "# print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa57d54",
   "metadata": {},
   "source": [
    "# 4. Imputation, Mapping and Encoding for 'Race' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d4a0a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHITE                                      112900\n",
      "BLACK OR AFRICAN AMERICAN                    7436\n",
      "SOME OTHER RACE                              1125\n",
      "ASIAN                                        1076\n",
      "Unknown                                       458\n",
      "AMERICAN INDIAN OR ALASKAN NATIVE             211\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLAND        49\n",
      "NaN                                             6\n",
      "Name: Race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the 'Race' column\n",
    "print(data['Race'].value_counts(dropna=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0398e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for 'Race' column after replacing 'Unknown' with NaN:\n",
      "WHITE                                      112900\n",
      "BLACK OR AFRICAN AMERICAN                    7436\n",
      "SOME OTHER RACE                              1125\n",
      "ASIAN                                        1076\n",
      "NaN                                           464\n",
      "AMERICAN INDIAN OR ALASKAN NATIVE             211\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLAND        49\n",
      "Name: Race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Unknown' with NaN\n",
    "data['Race'] = data['Race'].replace('Unknown', np.nan)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Value counts for 'Race' column after replacing 'Unknown' with NaN:\")\n",
    "print(data['Race'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffb48e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Missing Values  Percentage Missing\n",
      "PATID                        0            0.000000\n",
      "Race                       464            0.376437\n",
      "Marital_Status              13            0.010547\n",
      "Comorbidities              639            0.518412\n",
      "Smoking_Status               0            0.000000\n",
      "Encounter Type               0            0.000000\n",
      "Target                       0            0.000000\n",
      "SBP below 120                0            0.000000\n",
      "SBP 120-140                  0            0.000000\n",
      "SBP above 140                0            0.000000\n",
      "DBP below 80                 0            0.000000\n",
      "DBP 80-90                    0            0.000000\n",
      "DBP above 90                 0            0.000000\n",
      "Age_Grp_50-60                0            0.000000\n",
      "Age_Grp_60-70                0            0.000000\n",
      "Age_Grp_70-80                0            0.000000\n",
      "Age_Grp_80-90                0            0.000000\n",
      "Age_Grp_90-100               0            0.000000\n",
      "Sex_F                        0            0.000000\n",
      "Sex_M                        0            0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "percentage_missing = (missing_values / len(data)) * 100\n",
    "\n",
    "# Print the number of missing values and their percentage\n",
    "missing_data_summary = pd.DataFrame({'Missing Values': missing_values,'Percentage Missing': percentage_missing})\n",
    "\n",
    "print(missing_data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7acdfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATID               0\n",
      "Race              464\n",
      "Marital_Status     13\n",
      "Comorbidities     639\n",
      "Smoking_Status      0\n",
      "Encounter Type      0\n",
      "Target              0\n",
      "SBP below 120       0\n",
      "SBP 120-140         0\n",
      "SBP above 140       0\n",
      "DBP below 80        0\n",
      "DBP 80-90           0\n",
      "DBP above 90        0\n",
      "Age_Grp_50-60       0\n",
      "Age_Grp_60-70       0\n",
      "Age_Grp_70-80       0\n",
      "Age_Grp_80-90       0\n",
      "Age_Grp_90-100      0\n",
      "Sex_F               0\n",
      "Sex_M               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # Check the number of missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2521a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'Race' column after imputation:\n",
      "WHITE                                      113364\n",
      "BLACK OR AFRICAN AMERICAN                    7436\n",
      "SOME OTHER RACE                              1125\n",
      "ASIAN                                        1076\n",
      "AMERICAN INDIAN OR ALASKAN NATIVE             211\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLAND        49\n",
      "Name: Race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values in the 'Race' column\n",
    "\n",
    "data['Race'].fillna(data['Race'].mode()[0], inplace=True) \n",
    "\n",
    "# Verify the changes after imputation\n",
    "print(\"\\nValue counts for 'Race' column after imputation:\")\n",
    "print(data['Race'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27a826",
   "metadata": {},
   "source": [
    "# Define the Mapping Function for 'Race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4934aca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white                                      113364\n",
      "black or african american                    7436\n",
      "some other race                              1125\n",
      "asian                                        1076\n",
      "american indian or alaskan native             211\n",
      "native hawaiian or other pacific island        49\n",
      "Name: Race_Grouped, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Normalize and clean the string and Define the mapping function for 'Race'\n",
    "# Treat any other unknown or unexpected values as Unknown\n",
    "\n",
    "def map_race(status):\n",
    "    status = status.lower().strip()  \n",
    "    \n",
    "    if status in ['white', \n",
    "                  'black or african american', \n",
    "                  'some other race',\n",
    "                  'asian', \n",
    "                  'american indian or alaskan native', \n",
    "                  'native hawaiian or other pacific island']:\n",
    "        return status\n",
    "    else:\n",
    "        return 'unknown' \n",
    "\n",
    "# Apply the updated function to the 'Race' column\n",
    "data['Race_Grouped'] = data['Race'].apply(map_race)\n",
    "\n",
    "# Verify the changes\n",
    "print(data['Race_Grouped'].value_counts(dropna=False))\n",
    "\n",
    "# One-hot encoding on the 'Race_Grouped' column\n",
    "data = pd.get_dummies(data, columns=['Race_Grouped'], prefix='Race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297e0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values and their counts in the 'Race' column after mapping\n",
    "race_counts = data.filter(like='Race_').sum()\n",
    "print(race_counts)\n",
    "\n",
    "# Display the dataframe to verify encoding\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc9c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping old column names to new column names\n",
    "\n",
    "new_column_names = {\n",
    "    'Race_american indian or alaskan native': 'AMERICAN_IND/ALASKAN',\n",
    "    'ace_asian': 'ASIAN',\n",
    "    'Race_black or african american': 'BLACK/AFRIC_AMERICAN',\n",
    "    'Race_native hawaiian or other pacific island': 'NAT_HAWAIIN',\n",
    "    'Race_some other race': 'OTHER',\n",
    "    'Race_white': 'WHITE',\n",
    "}\n",
    "\n",
    "# Rename the columns using the rename method\n",
    "data.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Drop the original 'Race' column as it has been encoded\n",
    "data = data.drop(columns=['Race'], errors='ignore')\n",
    "\n",
    "# Verify the changes\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50eb5d3",
   "metadata": {},
   "source": [
    "# 5. Imputation, Mapping and Encoding 'Marital_Status' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41249386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Widowed' 'Divorced' 'Single' 'Separated' 'Unknown' nan\n",
      " 'Life Partner']\n",
      "Married         70676\n",
      "Single          20944\n",
      "Divorced        15038\n",
      "Widowed         13494\n",
      "Unknown          1517\n",
      "Separated        1500\n",
      "Life Partner       79\n",
      "NaN                13\n",
      "Name: Marital_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the 'Marital_Status' column\n",
    "unique_Marital_Status = data['Marital_Status'].unique()\n",
    "print(unique_Marital_Status)\n",
    "\n",
    "# Verify the unique values\n",
    "print(data['Marital_Status'].value_counts(dropna=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af59bd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for 'Marital_Status' column after replacing 'Unknown' with NaN:\n",
      "Married         70676\n",
      "Single          20944\n",
      "Divorced        15038\n",
      "Widowed         13494\n",
      "NaN              1530\n",
      "Separated        1500\n",
      "Life Partner       79\n",
      "Name: Marital_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Unknown' with NaN in the 'Marital_Status' column\n",
    "data['Marital_Status'] = data['Marital_Status'].replace('Unknown', np.nan)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Value counts for 'Marital_Status' column after replacing 'Unknown' with NaN:\")\n",
    "print(data['Marital_Status'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a1c4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'Marital_Status' column after imputation:\n",
      "Married         72206\n",
      "Single          20944\n",
      "Divorced        15038\n",
      "Widowed         13494\n",
      "Separated        1500\n",
      "Life Partner       79\n",
      "Name: Marital_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values in the 'Marital_Status' column\n",
    "\n",
    "mode_value = data['Marital_Status'].mode()[0]\n",
    "data['Marital_Status'].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Verify the changes after imputation\n",
    "print(\"\\nValue counts for 'Marital_Status' column after imputation:\")\n",
    "print(data['Marital_Status'].value_counts(dropna=False))\n",
    "\n",
    "# One-hot encoding on the 'Marital_Status' column\n",
    "data = pd.get_dummies(data, columns=['Marital_Status'], prefix='Marital_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6b3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe to verify encoding\n",
    "\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff4fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding created new columns for each marital status value. We'll use a dictionary to map old column names to the new ones.\n",
    "\n",
    "\n",
    "new_column_names = {\n",
    "    'Marital_Status_Divorced': 'Divorced',\n",
    "    'Marital_Status_Life Partner': 'Life Partner',\n",
    "    'Marital_Status_Married': 'Married',\n",
    "    'Marital_Status_Separated': 'Separated',\n",
    "    'Marital_Status_Single': 'Single',\n",
    "    'Marital_Status_Widowed': 'Widowed'\n",
    "}\n",
    "\n",
    "# Rename the columns using the rename method\n",
    "data.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "\n",
    "# Verify the changes\n",
    "print(data.columns)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb92566",
   "metadata": {},
   "source": [
    "# 6. Mapping and Encoding 'Encounter Type' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f39b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the value counts for the 'Encounter Type' column\n",
    "\n",
    "encounter_type_counts = data['Encounter Type'].value_counts()\n",
    "print(\"Encounter Type Counts:\")\n",
    "print(encounter_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a9daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'Encounter Type' values into separate columns\n",
    "split_encounters = data['Encounter Type'].str.get_dummies(sep=',')\n",
    "\n",
    "# Concatenate the original DataFrame with the new one hot encoded columns\n",
    "data = pd.concat([data, split_encounters], axis=1)\n",
    "\n",
    "# Drop the original 'Encounter Type' column\n",
    "data = data.drop(columns=['Encounter Type'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Updated DataFrame with One Hot Encoding for 'Encounter Type':\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9cc1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the new one hot encoded columns\n",
    "\n",
    "encoded_columns = split_encounters.columns\n",
    "print(\"One Hot Encoded Columns for 'Encounter Type':\")\n",
    "print(data[encoded_columns].head())\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d55694",
   "metadata": {},
   "source": [
    "# Rename the columns 'EMERGENCY' to 'EcType_ED', 'INPATIENT' to 'EcType_IP', and 'OUTPATIENT' to 'EcType_AV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11d7e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the specified columns\n",
    "\n",
    "data = data.rename(columns={\n",
    "    'EMERGENCY': 'EcType_ED',\n",
    "    'INPATIENT': 'EcType_IP',\n",
    "    'OUTPATIENT': 'EcType_AV'\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(data.info())\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca6ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177d212",
   "metadata": {},
   "source": [
    "# 7. Imputing, Mapping and Encoding for 'Comorbidities' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e333764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the number of missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75e273c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the 'Comorbidities' column\n",
    "\n",
    "unique_Comorbidities = data['Comorbidities'].unique()\n",
    "print(unique_Comorbidities)\n",
    "\n",
    "# Verify the new columns and their unique values\n",
    "#print(data[['Comorbidities']].head())\n",
    "print(data['Comorbidities'].value_counts(dropna=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2999d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of specific diseases that we want to encode\n",
    "\n",
    "diseases_to_encode = [\n",
    "    'Diabetes', 'Type 2 Diabetes Mellitus', 'Epilepsy', 'Depression', 'Obesity', 'Stroke', 'Anxiety', 'Hypertension',\n",
    "    'Hyperlipidemia', 'Cardiovascular Disease', 'Sleep Disorder', 'Headache', 'Periodontitis', 'Concussion',\n",
    "    'Heart Disease', 'Sleep Apnea', 'Insomnia', 'Kidney Disease', 'Cholesterol', 'Vitamin D Deficiency',\n",
    "    'Enlarge Prostate', 'Osteoporosis', 'Bone Disease', 'Depressive Disorder'\n",
    "]\n",
    "\n",
    "# Define the function to create a new column for each disease\n",
    "\n",
    "def map_comorbidities(comorbidities, disease):\n",
    "    if pd.isna(comorbidities):\n",
    "        return 0\n",
    "    return 1 if disease.lower() in comorbidities.lower() else 0\n",
    "\n",
    "# Create new columns for each disease\n",
    "\n",
    "for disease in diseases_to_encode:\n",
    "    data[disease.replace(' ', '_')] = data['Comorbidities'].apply(lambda x: map_comorbidities(x, disease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7c46b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count of each newly created disease column\n",
    "\n",
    "for disease in diseases_to_encode:\n",
    "    column_name = disease.replace(' ', '_')\n",
    "    count = data[column_name].sum()\n",
    "    print(f\"Count of {disease}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21a415a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe to verify encoding\n",
    "\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf0dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the changes\n",
    "print(data.head())\n",
    "\n",
    "# Drop the original 'Comorbidities' and 'Osteoporosis' columns after encoding\n",
    "data.drop(columns=['Comorbidities', 'Osteoporosis'], inplace=True)\n",
    "\n",
    "# Display the dataframe\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c409c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the 'Targer' column to the end\n",
    "target_col = data.pop('Target')\n",
    "data['Target'] = target_col\n",
    "\n",
    "# Print the DataFrame info to verify the changes\n",
    "print(data.info())\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898b8ee",
   "metadata": {},
   "source": [
    "# Save the Preprocessing DataFrame to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file for ML analysis\n",
    "\n",
    "data.to_csv('Combined_ML_3Yrs_ML_Analysis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
